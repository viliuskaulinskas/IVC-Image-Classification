{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score #sreeni\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import numpy as np\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import transforms, utils\n",
    "# import os, os.path\n",
    "# import random\n",
    "# from skimage import io, transform\n",
    "# import torchvision.models as models\n",
    "# from PIL import Image\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# import statistics\n",
    "# from scipy import signal\n",
    "\n",
    "# from data_providers import CatDogDataset, test_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transform = transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "#     ])\n",
    "\n",
    "set_list = ['A', 'B', 'C']\n",
    "batch_size = 16\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "root_dir = '../catdog/'\n",
    "\n",
    "# use gpu if it is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(root_dir, class_name, pert_list, set_list, batch_size, device, criterion):\n",
    "    \n",
    "    acc_mean_list = []\n",
    "    acc_std_list = []\n",
    "    for p in pert_list:\n",
    "        \n",
    "        acc_list = []\n",
    "        for testset in set_list:\n",
    "            set_name = testset + '_test'\n",
    "            \n",
    "            image_dataset = class_name(root_dir, \n",
    "                                set_name,\n",
    "                                data_transform,\n",
    "                                p)\n",
    "            dataloader = DataLoader(image_dataset, \n",
    "                                 batch_size = batch_size, \n",
    "                                 shuffle=True, \n",
    "                                 num_workers=2)\n",
    "            dataset_size = len(image_dataset)\n",
    "            \n",
    "            model = models.resnet18()\n",
    "            model.fc = nn.Linear(512, 2)\n",
    "            model_path = './models/' + testset + '_astest'\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            model = model.to(device)\n",
    "            \n",
    "            acc = test_model(model, dataloader,\n",
    "                              dataset_size, device,\n",
    "                              criterion)\n",
    "            acc_list.append(acc.item())\n",
    "            \n",
    "        acc_mean = statistics.mean(acc_list)\n",
    "        acc_std = statistics.stdev(acc_list)\n",
    "        \n",
    "        acc_mean_list.append(acc_mean)\n",
    "        acc_std_list.append(acc_std)\n",
    "        \n",
    "    return acc_mean_list, acc_std_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gaussian pixel noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPN(CatDogDataset):\n",
    "    def __init__(self, root_dir, set_name, transform, std):\n",
    "        super().__init__(root_dir, set_name, transform)\n",
    "        self.std = std\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image_name, target = self.data[index][0], self.data[index][1]\n",
    "        img = io.imread(self.root_dir + image_name)\n",
    "\n",
    "    \n",
    "        if len(img.shape) == 2:\n",
    "            img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "            \n",
    "        noise = np.rint(np.random.normal(0, self.std, (224, 224, 3))).astype(np.uint8)\n",
    "        img = np.clip(img + noise, 0, 255)\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, np.array([target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/A_astest'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-12f2a9ca2f8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m acc_mean_list, acc_std_list = testing(root_dir, GPN, std_list, set_list, \n\u001b[0;32m----> 4\u001b[0;31m             batch_size, device, criterion)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_mean_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_std_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d116f2c2acbf>\u001b[0m in \u001b[0;36mtesting\u001b[0;34m(root_dir, class_name, pert_list, set_list, batch_size, device, criterion)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./models/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_astest'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vilius/miniconda3/envs/mlp/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vilius/miniconda3/envs/mlp/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vilius/miniconda3/envs/mlp/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/A_astest'"
     ]
    }
   ],
   "source": [
    "std_list = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
    "\n",
    "acc_mean_list, acc_std_list = testing(root_dir, GPN, std_list, set_list, \n",
    "            batch_size, device, criterion)\n",
    "\n",
    "plt.errorbar(std_list, acc_mean_list, acc_std_list)\n",
    "plt.xticks(std_list)\n",
    "plt.xlabel('standard deviation')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('./robustness_graphs/gpn.png')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Gaussian blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GB(CatDogDataset):\n",
    "    def __init__(self, root_dir, set_name, transform, convolving_times):\n",
    "        super().__init__(root_dir, set_name, transform)\n",
    "        self.convolving_times = convolving_times\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image_name, target = self.data[index][0], self.data[index][1]\n",
    "        img = io.imread(self.root_dir + image_name)\n",
    "\n",
    "    \n",
    "        if len(img.shape) == 2:\n",
    "            img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "            \n",
    "            \n",
    "        mask = 1/16 * np.array([[1, 2, 1],\n",
    "                                [2, 4, 2],\n",
    "                                [1, 2, 1]])\n",
    "      \n",
    "        for n in range(self.convolving_times):\n",
    "            for c in range(3):\n",
    "                img[:, :, c] = signal.correlate2d(img[:,:,c], mask, \n",
    "                                                 boundary='fill', mode='same')\n",
    "                \n",
    "        img = np.clip(img, 0, 255)\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, np.array([target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "convolving_list = [x for x in range(10)]\n",
    "\n",
    "\n",
    "\n",
    "acc_mean_list, acc_std_list = testing(root_dir, GB, convolving_list, set_list, \n",
    "            batch_size, device, criterion)\n",
    "\n",
    "plt.errorbar(convolving_list, acc_mean_list, acc_std_list)\n",
    "plt.xticks(convolving_list)\n",
    "plt.xlabel('convolving time')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('./robustness_graphs/gb.png')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Image contrast increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICI(CatDogDataset):\n",
    "    def __init__(self, root_dir, set_name, transform, contrast):\n",
    "        super().__init__(root_dir, set_name, transform)\n",
    "        self.contrast = contrast\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image_name, target = self.data[index][0], self.data[index][1]\n",
    "        img = io.imread(self.root_dir + image_name)\n",
    "\n",
    "    \n",
    "        if len(img.shape) == 2:\n",
    "            img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "            \n",
    "      \n",
    "        img = np.rint(self.contrast * img).astype(np.uint8)\n",
    "                \n",
    "        img = np.clip(img, 0, 255)\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, np.array([target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "contrast = [1.0, 1.03, 1.06, 1.09, 1.12, 1.15, \n",
    "                   1.18, 1.21, 1.24, 1.27]\n",
    "\n",
    "# use gpu if it is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "acc_mean_list, acc_std_list = testing(root_dir, ICI, contrast, set_list, \n",
    "            batch_size, device, criterion)\n",
    "\n",
    "plt.errorbar(contrast, acc_mean_list, acc_std_list)\n",
    "plt.xticks(contrast)\n",
    "plt.xlabel('contrast')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('./robustness_graphs/ici.png')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Image contrast decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "contrast = [1.0, 0.90, 0.80, 0.70, 0.60, 0.50, 0.40, 0.30, 0.20, 0.10]\n",
    "\n",
    "# use gpu if it is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "acc_mean_list, acc_std_list = testing(root_dir, ICI, contrast, set_list, \n",
    "            batch_size, device, criterion)\n",
    "\n",
    "plt.errorbar(contrast, acc_mean_list, acc_std_list)\n",
    "plt.xticks(contrast)\n",
    "plt.xlim(1.1, 0.0)\n",
    "plt.xlabel('contrast')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('./robustness_graphs/icd.png')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Image brightness increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IB(CatDogDataset):\n",
    "    def __init__(self, root_dir, set_name, transform, brightness_increase):\n",
    "        super().__init__(root_dir, set_name, transform)\n",
    "        self.brightness_increase = brightness_increase\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image_name, target = self.data[index][0], self.data[index][1]\n",
    "        img = io.imread(self.root_dir + image_name)\n",
    "\n",
    "    \n",
    "        if len(img.shape) == 2:\n",
    "            img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "            \n",
    "      \n",
    "        img = (img + self.brightness_increase).astype(np.uint8)\n",
    "                \n",
    "        img = np.clip(img, 0, 255)\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, np.array([target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "brightness_increase = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45]\n",
    "\n",
    "# use gpu if it is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "acc_mean_list, acc_std_list = testing(root_dir, IB, brightness_increase, set_list, \n",
    "            batch_size, device, criterion)\n",
    "\n",
    "plt.errorbar(brightness_increase, acc_mean_list, acc_std_list)\n",
    "plt.xticks(brightness_increase)\n",
    "plt.xlabel('brightness_increase')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('./robustness_graphs/ibi.png')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Image brightness decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "brightness_increase = [0, -5, -10, -15, -20, -25, -30, -35, -40, -45]\n",
    "\n",
    "# use gpu if it is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "acc_mean_list, acc_std_list = testing(root_dir, IB, brightness_increase, set_list, \n",
    "            batch_size, device, criterion)\n",
    "\n",
    "plt.errorbar(brightness_increase, acc_mean_list, acc_std_list)\n",
    "plt.xticks(brightness_increase)\n",
    "plt.xlim(5, -50)\n",
    "plt.xlabel('brightness_decrease')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('./robustness_graphs/ibd.png')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. HSV Hue noise increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HNI(CatDogDataset):\n",
    "    def __init__(self, root_dir, set_name, transform, std):\n",
    "        super().__init__(root_dir, set_name, transform)\n",
    "        self.std = std\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image_name, target = self.data[index][0], self.data[index][1]\n",
    "        img = io.imread(self.root_dir + image_name)\n",
    "\n",
    "    \n",
    "        if len(img.shape) == 2:\n",
    "            img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "        \n",
    "        \n",
    "        img = matplotlib.colors.rgb_to_hsv(img/255)\n",
    "\n",
    "        noise = np.random.normal(0, self.std, (224, 224))\n",
    "        img[:, :, 0] = img[:, :, 0] + noise\n",
    "\n",
    "        img[:, :, 0] = np.where(img[:, :, 0] > 1, img[:, :, 0] - 1,  img[:, :, 0])\n",
    "        img[:, :, 0] = np.where(img[:, :, 0] < 0, img[:, :, 0] + 1,  img[:, :, 0])\n",
    "\n",
    "        img = matplotlib.colors.hsv_to_rgb(img)\n",
    "        img = np.rint(img * 255).astype(np.uint8)\n",
    "        \n",
    "        \n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, np.array([target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "std_list = [0.00, 0.02, 0.04, 0.06, 0.08, 0.10, 0.12, 0.14, 0.16, 0.18]\n",
    "\n",
    "\n",
    "\n",
    "acc_mean_list, acc_std_list = testing(root_dir, HNI, std_list, set_list, \n",
    "            batch_size, device, criterion)\n",
    "\n",
    "plt.errorbar(std_list, acc_mean_list, acc_std_list)\n",
    "plt.xticks(std_list)\n",
    "plt.xlabel('std')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('./robustness_graphs/hni.png')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. HSV Saturation noise increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNI(CatDogDataset):\n",
    "    def __init__(self, root_dir, set_name, transform, std):\n",
    "        super().__init__(root_dir, set_name, transform)\n",
    "        self.std = std\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image_name, target = self.data[index][0], self.data[index][1]\n",
    "        img = io.imread(self.root_dir + image_name)\n",
    "\n",
    "    \n",
    "        if len(img.shape) == 2:\n",
    "            img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "        \n",
    "        \n",
    "        img = matplotlib.colors.rgb_to_hsv(img/255)\n",
    "\n",
    "        noise = np.random.normal(0, self.std, (224, 224))\n",
    "        img[:, :, 1] = img[:, :, 1] + noise\n",
    "        \n",
    "        img = np.clip(img, 0.0, 1.0)\n",
    "\n",
    "\n",
    "        img = matplotlib.colors.hsv_to_rgb(img)\n",
    "        img = np.rint(img * 255).astype(np.uint8)\n",
    "        \n",
    "        \n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, np.array([target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_list = [0.00, 0.02, 0.04, 0.06, 0.08, 0.10, 0.12, 0.14, 0.16, 0.18]\n",
    "\n",
    "\n",
    "\n",
    "acc_mean_list, acc_std_list = testing(root_dir, SNI, std_list, set_list, \n",
    "            batch_size, device, criterion)\n",
    "\n",
    "plt.errorbar(std_list, acc_mean_list, acc_std_list)\n",
    "plt.xticks(std_list)\n",
    "plt.xlabel('std')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('./robustness_graphs/sni.png')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Occlusion of the image increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OII(CatDogDataset):\n",
    "    def __init__(self, root_dir, set_name, transform, edge_length):\n",
    "        super().__init__(root_dir, set_name, transform)\n",
    "        self.edge_length = edge_length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image_name, target = self.data[index][0], self.data[index][1]\n",
    "        img = io.imread(self.root_dir + image_name)\n",
    "\n",
    "    \n",
    "        if len(img.shape) == 2:\n",
    "            img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "        \n",
    "        # randomly choose the top-left pixel of the square region\n",
    "        \n",
    "        \n",
    "        x = random.randint(0, 224-self.edge_length)\n",
    "        y = random.randint(0, 224-self.edge_length)\n",
    "\n",
    "        img[x:x+self.edge_length, y: y+self.edge_length, :] = 0\n",
    "        \n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, np.array([target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "length_list = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45]\n",
    "\n",
    "\n",
    "\n",
    "acc_mean_list, acc_std_list = testing(root_dir, OII, length_list, set_list, \n",
    "            batch_size, device, criterion)\n",
    "\n",
    "plt.errorbar(length_list, acc_mean_list, acc_std_list)\n",
    "plt.xticks(length_list)\n",
    "plt.xlabel('length')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('./robustness_graphs/oii.png')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
